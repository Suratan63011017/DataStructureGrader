{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suratan63011017/DataStructures-And-Algorithm-Grader/blob/main/Untitled19132.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "buQ4dfXAy-Y8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a637c4a1-d2ce-4421-cd4e-65a93d717315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting tensorflow==2.9\n",
            "  Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (3.9.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.16.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (0.34.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (3.5)\n",
            "Collecting protobuf>=3.9.2 (from tensorflow==2.9)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow==2.9\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n6-fCx2Az2na"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import Model, Input\n",
        "import keras.utils as image\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D,BatchNormalization,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w0XUqm6G0Vgp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1"
      ],
      "metadata": {
        "id": "_4_9OQ0pdTp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q_kqne3Z7I3W"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"Focuss.jpg\")\n",
        "image = cv2.resize(image, (10,15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UStxRPqh7yEP"
      },
      "outputs": [],
      "source": [
        "reduce_factors = [1, 2, 4]\n",
        "scale_factors = [1 / factor for factor in reduce_factors]\n",
        "\n",
        "inter_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA]\n",
        "inter_texts = [\"INTER_NEAREST\", \"INTER_LINEAR\", \"INTER_CUBIC\", \"INTER_AREA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fpvkuO7L70im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fae41fc9-2e4e-4e48-d285-2ec17fd44163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[143 142 132]\n",
            "  [180 176 165]\n",
            "  [180 179 174]\n",
            "  [183 174 170]\n",
            "  [178 174 169]\n",
            "  [183 184 180]\n",
            "  [180 178 184]\n",
            "  [173 173 169]\n",
            "  [190 189 185]\n",
            "  [176 173 168]]\n",
            "\n",
            " [[253 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [174 143 122]\n",
            "  [171 142 121]\n",
            "  [173 146 125]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[247 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [217 209 189]\n",
            "  [230 223 211]\n",
            "  [232 226 215]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[199 163 123]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [232 205 179]\n",
            "  [226 199 172]\n",
            "  [227 199 172]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [169 169 169]\n",
            "  [193 194 184]\n",
            "  [175 175 186]\n",
            "  [194 195 190]\n",
            "  [186 181 170]\n",
            "  [183 183 183]\n",
            "  [180 173 169]\n",
            "  [193 193 193]\n",
            "  [193 194 192]]\n",
            "\n",
            " [[193 153 118]\n",
            "  [186 183 178]\n",
            "  [177 174 170]\n",
            "  [181 177 172]\n",
            "  [183 183 176]\n",
            "  [125 105 105]\n",
            "  [151 139 133]\n",
            "  [195 201 200]\n",
            "  [175 182 177]\n",
            "  [197 198 196]]\n",
            "\n",
            " [[181 141 106]\n",
            "  [190 186 181]\n",
            "  [178 175 170]\n",
            "  [193 198 196]\n",
            "  [144 136 146]\n",
            "  [106 105 130]\n",
            "  [109 120 152]\n",
            "  [176 191 209]\n",
            "  [129 134 127]\n",
            "  [171 180 172]]\n",
            "\n",
            " [[175 135 103]\n",
            "  [183 183 179]\n",
            "  [148 108  85]\n",
            "  [120  96  77]\n",
            "  [107  94 110]\n",
            "  [137 153 191]\n",
            "  [167 180 178]\n",
            "  [157 177 167]\n",
            "  [195 211 228]\n",
            "  [182 189 188]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [185 189 183]\n",
            "  [164 121 108]\n",
            "  [146 104  85]\n",
            "  [143 103  85]\n",
            "  [107  81  65]\n",
            "  [ 67  60  51]\n",
            "  [107  83  70]\n",
            "  [160 180 205]\n",
            "  [151 170 157]]\n",
            "\n",
            " [[121 108  76]\n",
            "  [177 182 180]\n",
            "  [ 86  75  65]\n",
            "  [198 205 232]\n",
            "  [124  89  75]\n",
            "  [ 98  70  68]\n",
            "  [166 179 178]\n",
            "  [183 191 192]\n",
            "  [152 164 158]\n",
            "  [130 176 145]]\n",
            "\n",
            " [[142 117  85]\n",
            "  [120 133 136]\n",
            "  [164 159 150]\n",
            "  [136 158 193]\n",
            "  [107  85  72]\n",
            "  [ 91  74  64]\n",
            "  [173 182 175]\n",
            "  [230 213 216]\n",
            "  [188 192 187]\n",
            "  [159 168 157]]\n",
            "\n",
            " [[152 127 101]\n",
            "  [138 136 154]\n",
            "  [162 189 175]\n",
            "  [112  85  71]\n",
            "  [167 183 212]\n",
            "  [ 94  81  73]\n",
            "  [101  75  68]\n",
            "  [134 139 139]\n",
            "  [122 160 148]\n",
            "  [173 173 167]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [ 93  97 104]\n",
            "  [115 140 124]\n",
            "  [ 88  65  59]\n",
            "  [ 70  58  52]\n",
            "  [175 188 214]\n",
            "  [ 94  73  60]\n",
            "  [108 119 111]\n",
            "  [112 146 112]\n",
            "  [165 154 154]]\n",
            "\n",
            " [[195 188 178]\n",
            "  [173 167 162]\n",
            "  [191 178 172]\n",
            "  [182 183 180]\n",
            "  [151 152 142]\n",
            "  [136 153 192]\n",
            "  [143 151 150]\n",
            "  [153 154 146]\n",
            "  [155 159 153]\n",
            "  [ 93 102 102]]\n",
            "\n",
            " [[131 158 144]\n",
            "  [132 145 117]\n",
            "  [119 150 121]\n",
            "  [123 121 117]\n",
            "  [203 209 203]\n",
            "  [175 176 172]\n",
            "  [153 161 160]\n",
            "  [178 175 166]\n",
            "  [175 175 167]\n",
            "  [ 82  91 107]]]\n",
            "[[[143 142 132]\n",
            "  [180 176 165]\n",
            "  [180 179 174]\n",
            "  [183 174 170]\n",
            "  [178 174 169]\n",
            "  [183 184 180]\n",
            "  [180 178 184]\n",
            "  [173 173 169]\n",
            "  [190 189 185]\n",
            "  [176 173 168]]\n",
            "\n",
            " [[253 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [174 143 122]\n",
            "  [171 142 121]\n",
            "  [173 146 125]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[247 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [217 209 189]\n",
            "  [230 223 211]\n",
            "  [232 226 215]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[199 163 123]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [232 205 179]\n",
            "  [226 199 172]\n",
            "  [227 199 172]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [169 169 169]\n",
            "  [193 194 184]\n",
            "  [175 175 186]\n",
            "  [194 195 190]\n",
            "  [186 181 170]\n",
            "  [183 183 183]\n",
            "  [180 173 169]\n",
            "  [193 193 193]\n",
            "  [193 194 192]]\n",
            "\n",
            " [[193 153 118]\n",
            "  [186 183 178]\n",
            "  [177 174 170]\n",
            "  [181 177 172]\n",
            "  [183 183 176]\n",
            "  [125 105 105]\n",
            "  [151 139 133]\n",
            "  [195 201 200]\n",
            "  [175 182 177]\n",
            "  [197 198 196]]\n",
            "\n",
            " [[181 141 106]\n",
            "  [190 186 181]\n",
            "  [178 175 170]\n",
            "  [193 198 196]\n",
            "  [144 136 146]\n",
            "  [106 105 130]\n",
            "  [109 120 152]\n",
            "  [176 191 209]\n",
            "  [129 134 127]\n",
            "  [171 180 172]]\n",
            "\n",
            " [[175 135 103]\n",
            "  [183 183 179]\n",
            "  [148 108  85]\n",
            "  [120  96  77]\n",
            "  [107  94 110]\n",
            "  [137 153 191]\n",
            "  [167 180 178]\n",
            "  [157 177 167]\n",
            "  [195 211 228]\n",
            "  [182 189 188]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [185 189 183]\n",
            "  [164 121 108]\n",
            "  [146 104  85]\n",
            "  [143 103  85]\n",
            "  [107  81  65]\n",
            "  [ 67  60  51]\n",
            "  [107  83  70]\n",
            "  [160 180 205]\n",
            "  [151 170 157]]\n",
            "\n",
            " [[121 108  76]\n",
            "  [177 182 180]\n",
            "  [ 86  75  65]\n",
            "  [198 205 232]\n",
            "  [124  89  75]\n",
            "  [ 98  70  68]\n",
            "  [166 179 178]\n",
            "  [183 191 192]\n",
            "  [152 164 158]\n",
            "  [130 176 145]]\n",
            "\n",
            " [[142 117  85]\n",
            "  [120 133 136]\n",
            "  [164 159 150]\n",
            "  [136 158 193]\n",
            "  [107  85  72]\n",
            "  [ 91  74  64]\n",
            "  [173 182 175]\n",
            "  [230 213 216]\n",
            "  [188 192 187]\n",
            "  [159 168 157]]\n",
            "\n",
            " [[152 127 101]\n",
            "  [138 136 154]\n",
            "  [162 189 175]\n",
            "  [112  85  71]\n",
            "  [167 183 212]\n",
            "  [ 94  81  73]\n",
            "  [101  75  68]\n",
            "  [134 139 139]\n",
            "  [122 160 148]\n",
            "  [173 173 167]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [ 93  97 104]\n",
            "  [115 140 124]\n",
            "  [ 88  65  59]\n",
            "  [ 70  58  52]\n",
            "  [175 188 214]\n",
            "  [ 94  73  60]\n",
            "  [108 119 111]\n",
            "  [112 146 112]\n",
            "  [165 154 154]]\n",
            "\n",
            " [[195 188 178]\n",
            "  [173 167 162]\n",
            "  [191 178 172]\n",
            "  [182 183 180]\n",
            "  [151 152 142]\n",
            "  [136 153 192]\n",
            "  [143 151 150]\n",
            "  [153 154 146]\n",
            "  [155 159 153]\n",
            "  [ 93 102 102]]\n",
            "\n",
            " [[131 158 144]\n",
            "  [132 145 117]\n",
            "  [119 150 121]\n",
            "  [123 121 117]\n",
            "  [203 209 203]\n",
            "  [175 176 172]\n",
            "  [153 161 160]\n",
            "  [178 175 166]\n",
            "  [175 175 167]\n",
            "  [ 82  91 107]]]\n",
            "[[[143 142 132]\n",
            "  [180 176 165]\n",
            "  [180 179 174]\n",
            "  [183 174 170]\n",
            "  [178 174 169]\n",
            "  [183 184 180]\n",
            "  [180 178 184]\n",
            "  [173 173 169]\n",
            "  [190 189 185]\n",
            "  [176 173 168]]\n",
            "\n",
            " [[253 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [174 143 122]\n",
            "  [171 142 121]\n",
            "  [173 146 125]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[247 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [217 209 189]\n",
            "  [230 223 211]\n",
            "  [232 226 215]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[199 163 123]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [232 205 179]\n",
            "  [226 199 172]\n",
            "  [227 199 172]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [169 169 169]\n",
            "  [193 194 184]\n",
            "  [175 175 186]\n",
            "  [194 195 190]\n",
            "  [186 181 170]\n",
            "  [183 183 183]\n",
            "  [180 173 169]\n",
            "  [193 193 193]\n",
            "  [193 194 192]]\n",
            "\n",
            " [[193 153 118]\n",
            "  [186 183 178]\n",
            "  [177 174 170]\n",
            "  [181 177 172]\n",
            "  [183 183 176]\n",
            "  [125 105 105]\n",
            "  [151 139 133]\n",
            "  [195 201 200]\n",
            "  [175 182 177]\n",
            "  [197 198 196]]\n",
            "\n",
            " [[181 141 106]\n",
            "  [190 186 181]\n",
            "  [178 175 170]\n",
            "  [193 198 196]\n",
            "  [144 136 146]\n",
            "  [106 105 130]\n",
            "  [109 120 152]\n",
            "  [176 191 209]\n",
            "  [129 134 127]\n",
            "  [171 180 172]]\n",
            "\n",
            " [[175 135 103]\n",
            "  [183 183 179]\n",
            "  [148 108  85]\n",
            "  [120  96  77]\n",
            "  [107  94 110]\n",
            "  [137 153 191]\n",
            "  [167 180 178]\n",
            "  [157 177 167]\n",
            "  [195 211 228]\n",
            "  [182 189 188]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [185 189 183]\n",
            "  [164 121 108]\n",
            "  [146 104  85]\n",
            "  [143 103  85]\n",
            "  [107  81  65]\n",
            "  [ 67  60  51]\n",
            "  [107  83  70]\n",
            "  [160 180 205]\n",
            "  [151 170 157]]\n",
            "\n",
            " [[121 108  76]\n",
            "  [177 182 180]\n",
            "  [ 86  75  65]\n",
            "  [198 205 232]\n",
            "  [124  89  75]\n",
            "  [ 98  70  68]\n",
            "  [166 179 178]\n",
            "  [183 191 192]\n",
            "  [152 164 158]\n",
            "  [130 176 145]]\n",
            "\n",
            " [[142 117  85]\n",
            "  [120 133 136]\n",
            "  [164 159 150]\n",
            "  [136 158 193]\n",
            "  [107  85  72]\n",
            "  [ 91  74  64]\n",
            "  [173 182 175]\n",
            "  [230 213 216]\n",
            "  [188 192 187]\n",
            "  [159 168 157]]\n",
            "\n",
            " [[152 127 101]\n",
            "  [138 136 154]\n",
            "  [162 189 175]\n",
            "  [112  85  71]\n",
            "  [167 183 212]\n",
            "  [ 94  81  73]\n",
            "  [101  75  68]\n",
            "  [134 139 139]\n",
            "  [122 160 148]\n",
            "  [173 173 167]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [ 93  97 104]\n",
            "  [115 140 124]\n",
            "  [ 88  65  59]\n",
            "  [ 70  58  52]\n",
            "  [175 188 214]\n",
            "  [ 94  73  60]\n",
            "  [108 119 111]\n",
            "  [112 146 112]\n",
            "  [165 154 154]]\n",
            "\n",
            " [[195 188 178]\n",
            "  [173 167 162]\n",
            "  [191 178 172]\n",
            "  [182 183 180]\n",
            "  [151 152 142]\n",
            "  [136 153 192]\n",
            "  [143 151 150]\n",
            "  [153 154 146]\n",
            "  [155 159 153]\n",
            "  [ 93 102 102]]\n",
            "\n",
            " [[131 158 144]\n",
            "  [132 145 117]\n",
            "  [119 150 121]\n",
            "  [123 121 117]\n",
            "  [203 209 203]\n",
            "  [175 176 172]\n",
            "  [153 161 160]\n",
            "  [178 175 166]\n",
            "  [175 175 167]\n",
            "  [ 82  91 107]]]\n",
            "[[[143 142 132]\n",
            "  [180 176 165]\n",
            "  [180 179 174]\n",
            "  [183 174 170]\n",
            "  [178 174 169]\n",
            "  [183 184 180]\n",
            "  [180 178 184]\n",
            "  [173 173 169]\n",
            "  [190 189 185]\n",
            "  [176 173 168]]\n",
            "\n",
            " [[253 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [174 143 122]\n",
            "  [171 142 121]\n",
            "  [173 146 125]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[247 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [217 209 189]\n",
            "  [230 223 211]\n",
            "  [232 226 215]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[199 163 123]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [232 205 179]\n",
            "  [226 199 172]\n",
            "  [227 199 172]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [169 169 169]\n",
            "  [193 194 184]\n",
            "  [175 175 186]\n",
            "  [194 195 190]\n",
            "  [186 181 170]\n",
            "  [183 183 183]\n",
            "  [180 173 169]\n",
            "  [193 193 193]\n",
            "  [193 194 192]]\n",
            "\n",
            " [[193 153 118]\n",
            "  [186 183 178]\n",
            "  [177 174 170]\n",
            "  [181 177 172]\n",
            "  [183 183 176]\n",
            "  [125 105 105]\n",
            "  [151 139 133]\n",
            "  [195 201 200]\n",
            "  [175 182 177]\n",
            "  [197 198 196]]\n",
            "\n",
            " [[181 141 106]\n",
            "  [190 186 181]\n",
            "  [178 175 170]\n",
            "  [193 198 196]\n",
            "  [144 136 146]\n",
            "  [106 105 130]\n",
            "  [109 120 152]\n",
            "  [176 191 209]\n",
            "  [129 134 127]\n",
            "  [171 180 172]]\n",
            "\n",
            " [[175 135 103]\n",
            "  [183 183 179]\n",
            "  [148 108  85]\n",
            "  [120  96  77]\n",
            "  [107  94 110]\n",
            "  [137 153 191]\n",
            "  [167 180 178]\n",
            "  [157 177 167]\n",
            "  [195 211 228]\n",
            "  [182 189 188]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [185 189 183]\n",
            "  [164 121 108]\n",
            "  [146 104  85]\n",
            "  [143 103  85]\n",
            "  [107  81  65]\n",
            "  [ 67  60  51]\n",
            "  [107  83  70]\n",
            "  [160 180 205]\n",
            "  [151 170 157]]\n",
            "\n",
            " [[121 108  76]\n",
            "  [177 182 180]\n",
            "  [ 86  75  65]\n",
            "  [198 205 232]\n",
            "  [124  89  75]\n",
            "  [ 98  70  68]\n",
            "  [166 179 178]\n",
            "  [183 191 192]\n",
            "  [152 164 158]\n",
            "  [130 176 145]]\n",
            "\n",
            " [[142 117  85]\n",
            "  [120 133 136]\n",
            "  [164 159 150]\n",
            "  [136 158 193]\n",
            "  [107  85  72]\n",
            "  [ 91  74  64]\n",
            "  [173 182 175]\n",
            "  [230 213 216]\n",
            "  [188 192 187]\n",
            "  [159 168 157]]\n",
            "\n",
            " [[152 127 101]\n",
            "  [138 136 154]\n",
            "  [162 189 175]\n",
            "  [112  85  71]\n",
            "  [167 183 212]\n",
            "  [ 94  81  73]\n",
            "  [101  75  68]\n",
            "  [134 139 139]\n",
            "  [122 160 148]\n",
            "  [173 173 167]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [ 93  97 104]\n",
            "  [115 140 124]\n",
            "  [ 88  65  59]\n",
            "  [ 70  58  52]\n",
            "  [175 188 214]\n",
            "  [ 94  73  60]\n",
            "  [108 119 111]\n",
            "  [112 146 112]\n",
            "  [165 154 154]]\n",
            "\n",
            " [[195 188 178]\n",
            "  [173 167 162]\n",
            "  [191 178 172]\n",
            "  [182 183 180]\n",
            "  [151 152 142]\n",
            "  [136 153 192]\n",
            "  [143 151 150]\n",
            "  [153 154 146]\n",
            "  [155 159 153]\n",
            "  [ 93 102 102]]\n",
            "\n",
            " [[131 158 144]\n",
            "  [132 145 117]\n",
            "  [119 150 121]\n",
            "  [123 121 117]\n",
            "  [203 209 203]\n",
            "  [175 176 172]\n",
            "  [153 161 160]\n",
            "  [178 175 166]\n",
            "  [175 175 167]\n",
            "  [ 82  91 107]]]\n",
            "[[[143 142 132]\n",
            "  [180 179 174]\n",
            "  [178 174 169]\n",
            "  [180 178 184]\n",
            "  [190 189 185]]\n",
            "\n",
            " [[247 241 235]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [230 223 211]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [193 194 184]\n",
            "  [194 195 190]\n",
            "  [183 183 183]\n",
            "  [193 193 193]]\n",
            "\n",
            " [[181 141 106]\n",
            "  [178 175 170]\n",
            "  [144 136 146]\n",
            "  [109 120 152]\n",
            "  [129 134 127]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [164 121 108]\n",
            "  [143 103  85]\n",
            "  [ 67  60  51]\n",
            "  [160 180 205]]\n",
            "\n",
            " [[142 117  85]\n",
            "  [164 159 150]\n",
            "  [107  85  72]\n",
            "  [173 182 175]\n",
            "  [188 192 187]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [115 140 124]\n",
            "  [ 70  58  52]\n",
            "  [ 94  73  60]\n",
            "  [112 146 112]]\n",
            "\n",
            " [[131 158 144]\n",
            "  [119 150 121]\n",
            "  [203 209 203]\n",
            "  [153 161 160]\n",
            "  [175 175 167]]]\n",
            "[[[208 204 197]\n",
            "  [218 216 214]\n",
            "  [198 189 182]\n",
            "  [174 160 150]\n",
            "  [219 218 216]]\n",
            "\n",
            " [[239 229 217]\n",
            "  [255 255 255]\n",
            "  [240 231 220]\n",
            "  [229 212 193]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 161 143]\n",
            "  [182 180 178]\n",
            "  [172 166 160]\n",
            "  [177 174 171]\n",
            "  [190 192 190]]\n",
            "\n",
            " [[182 161 142]\n",
            "  [160 144 132]\n",
            "  [124 122 144]\n",
            "  [152 167 177]\n",
            "  [169 179 179]]\n",
            "\n",
            " [[155 152 135]\n",
            "  [149 126 123]\n",
            "  [118  86  73]\n",
            "  [131 128 123]\n",
            "  [148 173 166]]\n",
            "\n",
            " [[138 128 119]\n",
            "  [144 148 147]\n",
            "  [115 106 105]\n",
            "  [160 152 150]\n",
            "  [161 173 165]]\n",
            "\n",
            " [[166 163 159]\n",
            "  [144 142 134]\n",
            "  [133 138 150]\n",
            "  [125 124 117]\n",
            "  [131 140 130]]\n",
            "\n",
            " [[132 152 130]\n",
            "  [121 136 119]\n",
            "  [189 192 188]\n",
            "  [166 168 163]\n",
            "  [128 133 137]]]\n",
            "[[[208 203 196]\n",
            "  [218 216 214]\n",
            "  [196 186 178]\n",
            "  [163 145 134]\n",
            "  [224 225 223]]\n",
            "\n",
            " [[244 234 222]\n",
            "  [255 255 255]\n",
            "  [246 237 225]\n",
            "  [237 218 196]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[177 155 138]\n",
            "  [174 171 170]\n",
            "  [170 164 156]\n",
            "  [177 175 172]\n",
            "  [187 189 187]]\n",
            "\n",
            " [[186 165 147]\n",
            "  [159 144 128]\n",
            "  [115 117 150]\n",
            "  [159 180 191]\n",
            "  [168 176 176]]\n",
            "\n",
            " [[161 163 146]\n",
            "  [147 122 120]\n",
            "  [115  73  54]\n",
            "  [121 117 110]\n",
            "  [143 173 167]]\n",
            "\n",
            " [[132 120 113]\n",
            "  [150 155 153]\n",
            "  [112 103 102]\n",
            "  [171 160 159]\n",
            "  [162 176 168]]\n",
            "\n",
            " [[169 165 163]\n",
            "  [153 149 142]\n",
            "  [128 136 153]\n",
            "  [117 114 103]\n",
            "  [130 140 127]]\n",
            "\n",
            " [[128 149 126]\n",
            "  [105 122 105]\n",
            "  [204 207 199]\n",
            "  [165 168 164]\n",
            "  [129 133 138]]]\n",
            "[[[208 204 197]\n",
            "  [218 216 214]\n",
            "  [198 189 182]\n",
            "  [174 160 150]\n",
            "  [219 218 216]]\n",
            "\n",
            " [[239 229 217]\n",
            "  [255 255 255]\n",
            "  [240 231 220]\n",
            "  [229 212 193]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[183 161 143]\n",
            "  [182 180 178]\n",
            "  [172 166 160]\n",
            "  [177 174 171]\n",
            "  [190 192 190]]\n",
            "\n",
            " [[182 161 142]\n",
            "  [160 144 132]\n",
            "  [124 122 144]\n",
            "  [152 167 177]\n",
            "  [169 179 179]]\n",
            "\n",
            " [[155 152 135]\n",
            "  [149 126 123]\n",
            "  [118  86  73]\n",
            "  [131 128 123]\n",
            "  [148 173 166]]\n",
            "\n",
            " [[138 128 119]\n",
            "  [144 148 147]\n",
            "  [115 106 105]\n",
            "  [160 152 150]\n",
            "  [161 173 165]]\n",
            "\n",
            " [[166 163 159]\n",
            "  [144 142 134]\n",
            "  [133 138 150]\n",
            "  [125 124 117]\n",
            "  [131 140 130]]\n",
            "\n",
            " [[132 152 130]\n",
            "  [121 136 119]\n",
            "  [189 192 188]\n",
            "  [166 168 163]\n",
            "  [128 133 137]]]\n",
            "[[[143 142 132]\n",
            "  [178 174 169]]\n",
            "\n",
            " [[183 137 106]\n",
            "  [194 195 190]]\n",
            "\n",
            " [[136 130 100]\n",
            "  [143 103  85]]\n",
            "\n",
            " [[204 200 191]\n",
            "  [ 70  58  52]]]\n",
            "[[[255 255 255]\n",
            "  [198 179 161]]\n",
            "\n",
            " [[183 180 175]\n",
            "  [123 117 130]]\n",
            "\n",
            " [[137 137 133]\n",
            "  [132 126 121]]\n",
            "\n",
            " [[154 160 143]\n",
            "  [152 160 169]]]\n",
            "[[[255 255 255]\n",
            "  [190 168 146]]\n",
            "\n",
            " [[183 184 183]\n",
            "  [102  93 108]]\n",
            "\n",
            " [[128 129 123]\n",
            "  [135 134 130]]\n",
            "\n",
            " [[161 165 146]\n",
            "  [148 159 172]]]\n",
            "[[[230 226 221]\n",
            "  [210 198 186]]\n",
            "\n",
            " [[177 162 149]\n",
            "  [156 157 163]]\n",
            "\n",
            " [[146 139 131]\n",
            "  [131 118 113]]\n",
            "\n",
            " [[146 149 139]\n",
            "  [145 147 147]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a 4x4 grid to display the resized images\n",
        "fig, axs = plt.subplots(len(reduce_factors), len(inter_methods), figsize=(12, 12))\n",
        "\n",
        "# Iterate through each combination of scale factors and interpolation methods\n",
        "for i, scale_factor in enumerate(scale_factors):\n",
        "    for j, inter_method in enumerate(inter_methods):\n",
        "        # Resize the image using the current scale factor and interpolation method\n",
        "        resized_image = cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=inter_method)\n",
        "        print(resized_image)\n",
        "        # Display the resized image using Matplotlib\n",
        "        axs[i, j].imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "        axs[i, j].set_title(f\"Scale: {1/scale_factor:.2f}, {inter_texts[j]}\")\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.2"
      ],
      "metadata": {
        "id": "FO0hLwhOdZxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"Focuss.jpg\")\n",
        "image = cv2.resize(image, (400,600))"
      ],
      "metadata": {
        "id": "vcblpUk3F2j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUKC32PkS2gq"
      },
      "outputs": [],
      "source": [
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 10\n",
        "    noise_factor = 5\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    # print(noisy_image.shape)\n",
        "    # print(type(noisy_image))\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT9K2ay1F6hW"
      },
      "outputs": [],
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "\n",
        "# Define fill modes\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "image = img_to_array(image)\n",
        "# Create a list to store augmented images\n",
        "augmented_images = []\n",
        "\n",
        "# Loop through each fill mode\n",
        "for fill_mode in fill_modes:\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=rotation_range,\n",
        "        width_shift_range=width_shift_range,\n",
        "        height_shift_range=height_shift_range,\n",
        "        shear_range=shear_range,\n",
        "        zoom_range=zoom_range,\n",
        "        horizontal_flip=horizontal_flip,\n",
        "        preprocessing_function=add_noise,\n",
        "        fill_mode=fill_mode\n",
        "    )\n",
        "\n",
        "    # Generate augmented images and add them to the list\n",
        "    augmented_batch = datagen.flow(np.expand_dims(image, 0), batch_size=1)\n",
        "    for i in range(1, 6):\n",
        "        batch = augmented_batch.next()\n",
        "        im_result = batch[0].astype('uint8') # choose first\n",
        "        augmented_images.append(im_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imJbP8QRV2qI"
      },
      "outputs": [],
      "source": [
        "# Define the figure size (adjust as needed)\n",
        "fig_width = 10\n",
        "fig_height = 15\n",
        "\n",
        "# Create a larger figure to display the augmented images\n",
        "plt.figure(figsize=(fig_width, fig_height))\n",
        "\n",
        "# Iterate through the augmented images and display them\n",
        "for i, augmented_image in enumerate(augmented_images):\n",
        "    plt.subplot(4, len(fill_modes)+1, i + 1)  # Create a subplot for each image\n",
        "    plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(augmented_images)"
      ],
      "metadata": {
        "id": "s5TaTOVnx_yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3"
      ],
      "metadata": {
        "id": "QM4augWDdh6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vuNOc6qwlLgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "AGckqIT2KC1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "at8BCMnZoanK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(128, (3, 3), activation='relu', padding='same')(x8)\n",
        "x10 = MaxPool2D((2, 2), strides=(2, 2))(x9)\n",
        "\n",
        "# Layer 3\n",
        "x11 = Conv2D(64, (3, 3), activation='relu', padding='same')(x10)\n",
        "\n",
        "# Layer 4\n",
        "x12 = Conv2D(64, (3, 3), activation='relu', padding='same')(x11)\n",
        "\n",
        "x13 = UpSampling2D((2, 2))(x12)\n",
        "\n",
        "x14 = Conv2D(128, (3, 3), activation='relu', padding='same')(x13)\n",
        "\n",
        "\n",
        "x15 = Conv2D(256, (3, 3), activation='relu', padding='same')(x14)\n",
        "\n",
        "\n",
        "x16 = Conv2D(1, (3, 3), activation='relu', padding='same')(x15)\n",
        "x17 = Dropout(0.1)(x16)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x17)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "2b_Gy4TsqZoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "CcqD4YRueeBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "g-5S8g0dQYi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l5CEapkDJuOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hHn53JrsSs99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# noise std = 0.5, noise_factor = 0.3"
      ],
      "metadata": {
        "id": "l9JHdVtTdyUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "dFEMoUhhd9yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "Uff2afEjd9yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "LziMy5Xgd9yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "a5MSMj_5d9yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "p2rRfq19d9yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "P_uC1TuRd9yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x5EIyRWed9yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "atW7BRTKd9yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# noise std = 0.1, noise_factor = 0.2"
      ],
      "metadata": {
        "id": "nTk8Qocuey67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.1\n",
        "    noise_factor = 0.2\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "kRScSO9Tey7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "cYGzuTLOey7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "a6Ots-S4ey7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "RvhYaM4Mey7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "AWRdvLeXey7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "UqE3r5vmey7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VuzyEShZey7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jhAy2rI9ey7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# epoch = 35"
      ],
      "metadata": {
        "id": "jyZtLEIde7ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3An2P6U5e7cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "4xu3-n-Ge7cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "FuVM8phye7cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "Ea1zpNBFe7cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=35,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "sy8Hlywpe7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "fo6pGqCHe7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhrQhdF2e7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "khhUG20fe7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# epoch = 70"
      ],
      "metadata": {
        "id": "3RiXAhyTfbP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TBfITv7ffbP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "Rf9nnXFnfbP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "_LPrKO1_fbP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "fQmyjpkjfbP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "rqNzIglyfbP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "QMK0p8SmfbP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fr6qeCXAfbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIWnUnE8fbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# batch_size = 128\n"
      ],
      "metadata": {
        "id": "GN_3L9w3fiVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vOyHxEA-fiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "bGGrhPRmfiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "97ee_-3ufiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "Zsoy4eUKfiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "r4F1h3UCfiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "7Q7clEN1fiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-7VPfr4gfiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EsO-FvRrfiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# batch_size = 256"
      ],
      "metadata": {
        "id": "zYIN4Sg6fv39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IJbZ-fsMfv4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "bKN1CUu8fv4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "yO2GORSYfv4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "sLzvfGb8fv4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "Y5P2Ictlfv4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "SRAwKhUzfv4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MZp_H90tfv4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UL9LIMLLfv4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "wo84nZXxf6zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7HF2xVwf6zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "L3DaAKcif6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "LlkNumS0f6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "H1H5uCeHf6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "PfKo47Plf6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "R3dXL0huf6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ax3msstQf6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zClKHAGUf6zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# learning_rate = 0.0003"
      ],
      "metadata": {
        "id": "f29eAm8bgK-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "WgcWXdeigK-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "zezml2RKgK-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "zYkH2SSugK-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "U48qcKN5gK-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "W4BzSne2gK-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "TPn5NuofgK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ES3D5ROgK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcdRUyo4gK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# original convolution node"
      ],
      "metadata": {
        "id": "YHoGvhLMgUx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vGrPCjBXgUx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "LfcxfmY_gUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "liTXWJIIgUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "# Layer 1\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(1, (3, 3), activation='relu', padding='same')(x8)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x9)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "QJZnVapAgUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "LYoquTXqgUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "WLqTH3hAgUx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YwSJV2nqgUx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKCLHg1rgUx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# double convolution + dropout"
      ],
      "metadata": {
        "id": "xnYhcYv8gtQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation_range = 30  # Degrees\n",
        "width_shift_range = 0.2  # Fraction of total width\n",
        "height_shift_range = 0.2  # Fraction of total height\n",
        "shear_range = 0.2  # Shear angle in radians\n",
        "zoom_range = 0.2  # Random zoom range\n",
        "horizontal_flip = True  # Allow horizontal flipping\n",
        "fill_modes = ['constant', 'nearest', 'reflect', 'wrap']\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "\n",
        "# Split the training data into train, test, and validation sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "x_train, x_val = train_test_split(x_train, random_state=random_state, test_size=(1/6))\n",
        "# x_test, x_val = train_test_split(x_test, random_state=random_state, test_size=0.5)\n",
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "# Prepare Gaussian Noise Function\n",
        "def add_noise(image):\n",
        "    noise_mean = 0\n",
        "    noise_std = 0.5\n",
        "    noise_factor = 0.3\n",
        "    noisy_image = image + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape))\n",
        "    return noisy_image\n",
        "\n",
        "noisy_x_train = []\n",
        "noisy_x_val = []\n",
        "noisy_x_test = []\n",
        "\n",
        "# Define noise parameters\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=add_noise\n",
        ")\n",
        "\n",
        "# # Example usage of datagen to generate augmented images\n",
        "# # This is typically used in a loop to generate batches of augmented images during training\n",
        "# batch_size = 32\n",
        "# augmented_images = datagen.flow(x_train.reshape(-1, 28, 28, 1), batch_size=batch_size)\n",
        "# print(len(augmented_images))\n",
        "\n",
        "# # Display the first 10 augmented images from the first batch\n",
        "# for i in range(10):\n",
        "#     augmented_image = augmented_images.next()\n",
        "#     plt.figure(figsize=(2, 2))\n",
        "#     plt.imshow(augmented_image[0].reshape(28, 28), cmap='viridis')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "# augmented_images = []\n",
        "\n",
        "# Generate augmented images for each image in x_train\n",
        "for image in x_train:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_train.append(augmented_image)\n",
        "print(len(noisy_x_train))\n",
        "for image in x_val:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_val.append(augmented_image)\n",
        "print(len(noisy_x_val))\n",
        "\n",
        "for image in x_test:\n",
        "    # Expand dimensions to (1, 28, 28, 1)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    augmented_image = datagen.flow(np.array([image]), batch_size=1).next()[0]\n",
        "    noisy_x_test.append(augmented_image)\n",
        "print(len(noisy_x_test))\n",
        "\n",
        "noisy_x_train = np.array(noisy_x_train)\n",
        "noisy_x_train = np.squeeze(noisy_x_train)\n",
        "noisy_x_val = np.array(noisy_x_val)\n",
        "noisy_x_val = np.squeeze(noisy_x_val)\n",
        "noisy_x_test = np.array(noisy_x_test)\n",
        "noisy_x_test = np.squeeze(noisy_x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(noisy_x_train.shape)\n",
        "print(noisy_x_val.shape)\n",
        "print(noisy_x_test.shape)\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "\n",
        "# Create a figure and axis for the grid\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 15))\n",
        "\n",
        "# Loop through the pairs of original and noisy images\n",
        "for i in range(num_rows):\n",
        "    # Display the original image\n",
        "    axes[i, 0].imshow(x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 0].set_title('Original')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display the noisy image\n",
        "    axes[i, 1].imshow(noisy_x_train[i].reshape(28, 28), cmap='viridis')\n",
        "    axes[i, 1].set_title('Noisy')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IYjgULPegtRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noisy_x_train = np.array(noisy_x_train)\n",
        "# noisy_x_train = np.squeeze(noisy_x_train)\n",
        "# noisy_x_val = np.array(noisy_x_val)\n",
        "# noisy_x_val = np.squeeze(noisy_x_val)\n",
        "# noisy_x_test = np.array(noisy_x_test)\n",
        "# noisy_x_test = np.squeeze(noisy_x_test)\n",
        "# print(noisy_x_train.shape)\n",
        "# print(noisy_x_val.shape)\n",
        "# print(noisy_x_test.shape)"
      ],
      "metadata": {
        "id": "QHvK5ekDgtRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "RIsdDMSvgtRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))\n",
        "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "\n",
        "# Layer 2\n",
        "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
        "x3 = MaxPool2D((2, 2), strides=(2, 2))(x2)\n",
        "\n",
        "# Layer 3\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
        "\n",
        "# Layer 4\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', padding='same')(x4)\n",
        "\n",
        "x6 = UpSampling2D((2, 2))(x5)\n",
        "\n",
        "x7 = Conv2D(128, (3, 3), activation='relu', padding='same')(x6)\n",
        "\n",
        "\n",
        "x8 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
        "\n",
        "# Layer 2\n",
        "x9 = Conv2D(128, (3, 3), activation='relu', padding='same')(x8)\n",
        "x10 = MaxPool2D((2, 2), strides=(2, 2))(x9)\n",
        "\n",
        "# Layer 3\n",
        "x11 = Conv2D(64, (3, 3), activation='relu', padding='same')(x10)\n",
        "\n",
        "# Layer 4\n",
        "x12 = Conv2D(64, (3, 3), activation='relu', padding='same')(x11)\n",
        "\n",
        "x13 = UpSampling2D((2, 2))(x12)\n",
        "\n",
        "x14 = Conv2D(128, (3, 3), activation='relu', padding='same')(x13)\n",
        "\n",
        "\n",
        "x15 = Conv2D(256, (3, 3), activation='relu', padding='same')(x14)\n",
        "\n",
        "\n",
        "x16 = Conv2D(1, (3, 3), activation='relu', padding='same')(x15)\n",
        "x17 = Dropout(0.1)(x16)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, x17)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "0bdmKhE8gtRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = autoencoder.fit(\n",
        "    noisy_x_train,\n",
        "    x_train,\n",
        "    epochs=70,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_x_val, x_val),\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "Jw6xaa88gtRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = autoencoder.predict(noisy_x_test)"
      ],
      "metadata": {
        "id": "J5bFDqbLgtRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim(0.025, 0.07)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Im7CwuJ8gtRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 5  # Number of images to display\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Noisy image\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_x_test[i])\n",
        "    plt.title('Noisy')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed image\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(predictions_test[i])\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "joSwM8eqgtRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNDF+RTe4zZoda/fkVmSOWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}